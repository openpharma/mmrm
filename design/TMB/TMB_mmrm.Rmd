---
title: "Try out fitting unstructured MMRM directly with TMB"
author: "Daniel Sabanes based on Ben Bolker example"
output: html_document
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Objective

Motivation: We still have trouble fitting a true MMRM (i.e. without residual
variance, and obtaining correct Satterthwaite) with `glmmTMB`, see https://github.com/glmmTMB/glmmTMB/blob/satterthwaite_df/glmmTMB/vignettes/satterthwaite_unstructured_example2.Rmd

So one idea is to directly use `TMB` since then we have more freedom how to define the model.
Plus `TMB` supports Hessian and Jacobian calculations (at least with latest 1.9.0 version)
which should help us with the Satterthwaite d.f. calculations to avoid `numDeriv::jacobian()`.

```{r}
setwd("/home/users/sabanesd/git/mmrm/design/TMB")
library(mmrm)
library(TMB)
library(lme4)
library(glmmTMB)
```

## Model fit with `glmmTMB`

Let's first fit the MMRM with `glmmTMB` such that we can compare the results
later.

```{r}
df <- fev_data
glmm_formula <- FEV1 ~ ARMCD * AVISIT + RACE + SEX + us(0 + AVISIT | USUBJID)
glmm_model <- glmmTMB(
  formula = glmm_formula,
  data = df,
  dispformula = ~0,
  REML = TRUE,
  control = glmmTMBControl(
    optimizer = optim,
    optArgs = list(method = "L-BFGS-B")
  )
)
```

So we get:

```{r}
logLik(glmm_model)
VarCorr(glmm_model)$cond[[1]]
```

## Model fit with `TMB`

### Compiling and loading

```{r}
compile(
  "TMB_mmrm.cpp", # Note: Modify cpp file to trigger run.
  flags = "-O0 -ggdb", # For debugging with gdb use these optional flags.
  framework = "TMBad" # Select the AD framework. Default is CppAD
)
dyn.load(dynlib("TMB_mmrm"))
```

### Collecting inputs

#### Data

```{r}
# DATA_MATRIX(X);               // Model matrix (dimension n x p).
# DATA_VECTOR(Y);               // Response vector (length n).
# DATA_IVECTOR(visits_zero);    // Zero-based Visits vector (length n).
# DATA_INTEGER(n_visits);       // Number of visits, which is the dimension of the covariance matrix.
# DATA_INTEGER(n_subjects);     // Number of subjects.
# DATA_IVECTOR(subject_inds);   // Starting indices for each subject (0-based) (length n_subjects).
# DATA_IVECTOR(subject_n_visits); // Number of observed visits for each subject (length n_subjects).

df <- fev_data
fixed_formula <- FEV1 ~ ARMCD * AVISIT + RACE + SEX
visit_var <- "AVISIT"
subject_var <- "USUBJID"
# Note that we include USUBJID here so that we can carry it with below.
full_formula <- update(fixed_formula, as.formula(paste("~ . +", subject_var)))
df <- df[order(df[[subject_var]], df[[visit_var]]), ]
head(df)
# Note that there are missing values in FEV1, the response here, the
# corresponding rows are discarded in the modeling below.

full_frame <- droplevels(model.frame(full_formula, data = df))
X <- model.matrix(fixed_formula, data = full_frame)
Y <- model.response(full_frame)
visits_zero <- as.integer(full_frame[[visit_var]]) - 1L
n_visits <- nlevels(full_frame[[visit_var]])
n_subjects <- nlevels(full_frame[[subject_var]])
subject_inds <- which(!duplicated(full_frame[[subject_var]])) - 1L
subject_n_visits <- c(tail(subject_inds, -1L), nrow(full_frame)) - subject_inds
identical(subject_n_visits, as.integer(table(full_frame[[subject_var]])))

tmb_data <- list(
  X = X,
  Y = Y,
  visits_zero = visits_zero,
  n_visits = n_visits,
  n_subjects = n_subjects,
  subject_inds = subject_inds,
  subject_n_visits = subject_n_visits
)
```

#### Parameters

```{r}
# PARAMETER_VECTOR(beta);       // Coefficient vector (length p).
# PARAMETER_VECTOR(theta);      // Covariance parameters (length k). Starts with log standard deviations
#                               // and continues with entries of lower triangular Cholesky factor.

tmb_parameters <- list(
  beta = rep(0, ncol(X)),
  theta = rep(0, n_visits * (n_visits + 1) / 2) # Because of unstructured covariance matrix.
)
```

### Building and fitting TMB

```{r}
tmb_object <- MakeADFun(
  data = tmb_data,
  parameters = tmb_parameters,
  # ADreport = TRUE,
  hessian = TRUE,
  intern = FALSE,
  random = "beta", # Integrate over beta to obtain REML estimate for theta.
  DLL = "TMB_mmrm", # We need to specify this because glmmTMB loads other DLLs.

  silent = TRUE # Otherwise we get a huge number of outer mgc messages.
)
```

Debugging works with `gdbsource("TMB_mmrm.R", interactive = TRUE)` and then
jumping into stack frames with `frame 3` e.g. and inspecting objects with `print`.
Note that Eigen vectors can be looked at with `print *vector.data()@5` e.g. if it
has 5 elements.
Breakpoints can be set with `std::abort();` in the C++ code.

```{r}
tmb_fit <- with(
  tmb_object,
  nlminb(
    start = par,
    objective = fn,
    gradient = gr
  )
)
stopifnot(tmb_fit$convergence == 0)
```

That looks good, it converged!

### Comparing results

Let's see if this gave the same result as `glmmTMB`!

#### Log-likelihood

The log-likelihood is:

```{r}
(tmb_log_lik <- -tmb_fit$objective)
all.equal(as.numeric(logLik(glmm_model)), tmb_log_lik)
```

#### Covariance estimate

And the covariance matrix estimate can be computed as follows from the `theta`
estimate (note that this is redoing the calculations from https://kaskr.github.io/adcomp/density_8hpp_source.html#l00253):

```{r}
get_cov_mat <- function(fit) {
  theta_est <- fit$par
  theta_len <- length(theta_est)
  n_visits <- floor(sqrt(2 * theta_len))
  sd_values <- exp(head(theta_est, n_visits))
  chol_values <- tail(theta_est, -n_visits)
  L <- matrix(data = 0, nrow = n_visits, ncol = n_visits)
  lower_tri_inds <- which(lower.tri(L), arr.ind = TRUE)
  lower_tri_inds <- lower_tri_inds[order(lower_tri_inds[, "row"], lower_tri_inds[, "col"]), ]
  L[lower_tri_inds] <- chol_values
  diag(L) <- 1
  LLt <- tcrossprod(L)
  D_inv_sqrt <- diag(1 / sqrt(diag(LLt)))
  corr_mat <- D_inv_sqrt %*% LLt %*% D_inv_sqrt
  sd_mat <- diag(sd_values)
  structure(
    sd_mat %*% corr_mat %*% sd_mat,
    stddev = sd_values,
    correlation = corr_mat
  )
}
```

So let's see:

```{r}
(tmb_cov_mat <- get_cov_mat(tmb_fit))
```

And we can compare that:

```{r}
glmm_cov_mat <- VarCorr(glmm_model)$cond[[1]]
all.equal(tmb_cov_mat, glmm_cov_mat, check.attributes = FALSE)
all.equal(attr(tmb_cov_mat, "stddev"), attr(glmm_cov_mat, "stddev"), check.attributes = FALSE)
all.equal(attr(tmb_cov_mat, "correlation"), attr(glmm_cov_mat, "correlation"), check.attributes = FALSE)
```

So that looks pretty good!

#### Fixed effect estimates

For this we need to run the `sdreport` function.

```{r}
tmb_sdreport <- sdreport(
  tmb_object,
  par.fixed = tmb_fit$par,
  getJointPrecision = TRUE,
  getReportCovariance = TRUE
)

(tmb_beta_est <- summary(tmb_sdreport, "random"))
```

We can compare this with `glmmTMB`:

```{r}
(glmm_beta_est <- summary(glmm_model)$coefficients$cond[, c(1, 2)])
all.equal(tmb_beta_est, glmm_beta_est, check.attributes = FALSE)
```

So this is fine!

#### Covariance parameter covariance matrix

We can look at that too, but like we parametrized `theta` right now
there will be differences because `glmmTMB` fits on the log-variance rather
than the log-sd scale.

```{r}
(tmb_theta_cov <- tmb_sdreport$cov.fixed)
```

#### Fixed effect covariance matrix

This is something we can compare.

```{r}
get_beta_cov <- function(sd_rep) {
  q_mat <- sd_rep$jointPrecision
  which_fixed <- which(rownames(q_mat) == "beta")
  q_marginal <- unname(glmmTMB:::GMRFmarginal(q_mat, which_fixed))
  solve(as.matrix(q_marginal))
}

tmb_beta_cov <- get_beta_cov(tmb_sdreport)
glmm_beta_cov <- vcov(glmm_model)$cond
all.equal(tmb_beta_cov, glmm_beta_cov, check.attributes = FALSE)
```

So this looks also good.

## Satterthwaite d.f.

Now let's see what we get with the Satterthwaite calculations.

```{r}
get_df <- function(tmb_object, tmb_fit, L) {
  tmb_sdreport <- sdreport(
    tmb_object,
    par.fixed = tmb_fit$par,
    getJointPrecision = TRUE
  )
  model_theta_vcov <- tmb_sdreport$cov.fixed
  model_theta_est <- tmb_fit$par
  model_beta_vcov <- get_beta_cov(tmb_sdreport)
  get_covbeta_theta <- function(theta) {
    sdr <- sdreport(
      tmb_object,
      par.fixed = theta,
      getJointPrecision = TRUE
    )
    get_beta_cov(sdr)
  }
  get_jac_list <- function(covbeta_fun, x_opt, ...) {
    jac_matrix <- numDeriv::jacobian(
      func = covbeta_fun,
      x = x_opt,
      ...
    )
    lapply(
      seq_len(ncol(jac_matrix)), # For each variance parameter.
      FUN = function(i) {
        # This column contains the p x p entries:
        jac_col <- jac_matrix[, i]
        p <- sqrt(length(jac_col))
        # Get p x p matrix.
        matrix(jac_col, nrow = p, ncol = p)
      }
    )
  }
  model_jac_theta <- get_jac_list(get_covbeta_theta, model_theta_est)
  get_gradient <- function(jac, L) {
    vapply(
      jac,
      function(x) sum(L * x %*% L), # = {L' Jac L}_i
      numeric(1L)
    )
  }
  model_grad_theta <- get_gradient(model_jac_theta, L)
  model_var_contrast <- drop(t(L) %*% model_beta_vcov %*% L)
  model_v_numerator <- 2 * model_var_contrast^2
  model_v_denominator <- sum(model_grad_theta * (model_theta_vcov %*% model_grad_theta))
  model_df_contrast <- model_v_numerator / model_v_denominator
  model_df_contrast
}
```

Let's try it out:

```{r}
L <- c(1, rep(0, 10)) # get the intercept only.
(df_intercept <- get_df(tmb_object, tmb_fit, L))
```

So we get around 219 d.f. here which is not completely off anymore, which
is nice, but still pretty far away from the 171 that we expect.
