---
title: "Details of the Model Fitting in `mmrm`"
package: mmrm
author:
  - name: Daniel Sabanés Bové
    email: daniel.sabanes_bove@roche.com
output:
  rmarkdown::html_document:
          theme: "spacelab"
          highlight: "kate"
          toc: true
          toc_float: true
vignette: |
  %\VignetteIndexEntry{Details of the Model Fitting in `mmrm`}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(mmrm)
```

Here we describe the exact model definition as well as the estimation algorithms
in detail.

## Model definition

The mixed model for repeated measures (MMRM) definition we are using in this package
is the following. Let $i = 1, \dotsc, n$ denote the subjects from which we observe
multiple observations $j = 1, \dotsc, m_i$ from total $m_i$ time points
$t_{ij} \in \{t_1, \dotsc, t_m\}$. Note that the number of time points for a specific
subject, $m_i$, can be smaller than $m$, when only a subset of the possible $m$
time points have been observed.

### Linear model

For each subject $i$ we observe a vector
\[
Y_i = (y_{i1}, \dotsc, y_{im_i})^\top \in \mathbb{R}^{m_i}
\]
and given a design matrix
\[
X_i \in \mathbb{R}^{m_i \times p}
\]
and a corresponding coefficient vector $\beta \in \mathbb{R}^{p}$ we assume
that the observations are multivariate normal distributed:
\[
Y_i \sim N(X_i\beta, \Sigma_i)
\]
where the covariance matrix $\Sigma_i \in \mathbb{R}^{m_i \times m_i}$ is derived
by subsetting the overall covariance matrix $\Sigma \in \mathbb{R}^{m \times m}$
appropriately by
\[
\Sigma_i = S_i^\top \Sigma S_i
\]
where the subsetting matrix $S_i \in \{0, 1\}^{m \times m_i}$ contains
in each of its $m_i$ columns contains a single 1 indicating which overall time point
is matching $t_{ij}$. Each row contains at most a single 1 but can also contain
only 0 if this time point was not observed.
For example, assume a subject was observed on time points
$1, 3, 4$ out of total $5$ then the subsetting matrix is
\[
S_i = \begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{pmatrix}.
\]
Note that this follows from the well known property of the multivariate normal
distribution that linear combinations of the random vector again have a
multivariate normal distribution with the correspondingly modified mean
vector and covariance matrix.

Conditional on the design matrices $X_i$, the coefficient vector $\beta$ and the
covariance matrix $\Sigma$ we assume that the observations are independent between
the subjects.

We can write the linear model for all subjects together as
\[
Y = X\beta + \epsilon
\]
where $Y \in \mathbb{R}^N$ combines all subject specific observations vectors $Y_i$
such that we have in total $N = \sum_{i = 1}^{m_i}$ observations,
$X \in \mathbb{R}^{N \times p}$ combines all subject specific design matrices
and $\epsilon \in \mathbb{R}^N$ has a multivariate normal distribution
\[
\epsilon \sim N(0, \Omega)
\]
where $\Omega \in \mathbb{R}^{N \times N}$ is block-diagonal containing the
subject specific $\Sigma_i$ covariance matrices on the diagonal and 0 in the
remaining entries.

### Covariance matrix model

The symmetric and positive definite covariance matrix
\[
\Sigma = \begin{pmatrix}
\sigma_1^2 & \sigma_{12} & \dots & \dots & \sigma_{1m} \\
\sigma_{21} & \sigma_2^2 & \sigma_{23} & \dots & \sigma_{2m}\\
\vdots & & \ddots & & \vdots \\
\vdots & & & \ddots & \vdots \\
\sigma_{m1} & \dots & \dots & \sigma_{m,m-1} & \sigma_m^2
\end{pmatrix}
\]
is parametrized by a vector of variance parameters
$\theta = (\theta_1, \dotsc, \theta_k)^\top$. There are many different choices
for how to model the covariance matrix and correspondingly $\theta$
has different interpretations. Since any covariance matrix has a unique Cholesky
factorization $\Sigma = LL^\top$ where $L$ is the lower triangular Cholesky factor,
we are going to use this below.

#### Unstructured covariance matrix

The most general model uses a saturated parametrization,
i.e. any covariance matrix could be represented in this form. Here we use
\[
L = D\tilde{L}
\]
where $D$ is the diagonal matrix of standard deviations, and $\tilde{L}$ is a
unit diagonal lower triangular matrix. Hence we start $\theta$ with the natural
logarithm of the standard deviations, followed by the row-wise filled entries
of $\tilde{L} = \{l_{ij}\}_{1 \leq j < i \leq m}$:
\[
\theta = (
  \log(\sigma_1), \dotsc, \log(\sigma_m),
  l_{21}, l_{31}, l_{32}, \dotsc, l_{m,m-1}
)^\top
\]
Here $\theta$ has $k = m(m+1)/2$ entries. For example for $m = 4$ time points
we need $k = 10$ variance parameters to model the unstructured covariance matrix.

Other covariance matrix choices are explained in a dedicated vignette (to do).

## Maximum Likelihood Estimation
