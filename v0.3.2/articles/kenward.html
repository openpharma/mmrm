<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mmrm">
<title>Kenward-Roger • mmrm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Kenward-Roger">
<meta property="og:description" content="mmrm">
<meta property="og:image" content="https://openpharma.github.io/mmrm/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-125641273-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125641273-1');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mmrm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Introduction</h6>
    <a class="dropdown-item" href="../articles/introduction.html">Package Introduction</a>
    <a class="dropdown-item" href="../articles/methodological_introduction.html">Mixed Models for Repeated Measures</a>
    <a class="dropdown-item" href="../articles/mmrm_review_methods.html">Comparison with other software</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Covariance Structures</h6>
    <a class="dropdown-item" href="../articles/covariance.html">Covariance Structures</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Degrees of Freedom</h6>
    <a class="dropdown-item" href="../articles/between_within.html">Between-Within</a>
    <a class="dropdown-item" href="../articles/kenward.html">Kenward-Roger</a>
    <a class="dropdown-item" href="../articles/satterthwaite.html">Satterthwaite</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Coefficient Covariance</h6>
    <a class="dropdown-item" href="../articles/coef_vcov.html">Coefficients Covariance Matrix Adjustment</a>
    <a class="dropdown-item" href="../articles/empirical_wls.html">Details of Weighted Least Square Empirical Covariance</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Algorithm Details</h6>
    <a class="dropdown-item" href="../articles/algorithm.html">Model Fitting Algorithm</a>
    <a class="dropdown-item" href="../articles/predict.html">Prediction and Simulation</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Developers</h6>
    <a class="dropdown-item" href="../articles/package_structure.html">Package Structure</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
<!-- start dropdown for versions --> <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-versions">Versions</a>
    <div class="dropdown-menu" aria-labelledby="dropdown-versions">
    <a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/main">main</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/latest-tag">latest-tag</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.14">v0.3.14</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.13">v0.3.13</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.12">v0.3.12</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.11">v0.3.11</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.10">v0.3.10</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.7">v0.3.7</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.6">v0.3.6</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.5">v0.3.5</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.4">v0.3.4</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.3">v0.3.3</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.2">v0.3.2</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.1">v0.3.1</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.3.0">v0.3.0</a>
<a class="dropdown-item" data-toggle="tooltip" title="" href="https://openpharma.github.io/mmrm/v0.2.2">v0.2.2</a>
</div>
</li>
<!-- end dropdown for versions -->
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-reports">Reports</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-reports">
    <a class="dropdown-item" href="../coverage-report/">Coverage report</a>
    <a class="dropdown-item" href="../unit-test-report/">Unit test report</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/openpharma/mmrm">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Kenward-Roger</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/openpharma/mmrm/blob/HEAD/vignettes/kenward.Rmd" class="external-link"><code>vignettes/kenward.Rmd</code></a></small>
      <div class="d-none name"><code>kenward.Rmd</code></div>
    </div>

    
    
<p>Here we describe the details of the calculations for the
Kenward-Roger degrees of freedom and the adjusted covariance matrix of
the coefficients.</p>
<div class="section level3">
<h3 id="model-definition">Model definition<a class="anchor" aria-label="anchor" href="#model-definition"></a>
</h3>
<p>The model definition is the same as what we have in <a href="algorithm.html">Details of the model fitting in
<code>mmrm</code></a>. We are using the same notations.</p>
<div class="section level4">
<h4 id="linear-model">Linear model<a class="anchor" aria-label="anchor" href="#linear-model"></a>
</h4>
<p>For each subject <span class="math inline">\(i\)</span> we observe a
vector <span class="math display">\[
Y_i = (y_{i1}, \dotsc, y_{im_i})^\top \in \mathbb{R}^{m_i}
\]</span> and given a design matrix <span class="math display">\[
X_i \in \mathbb{R}^{m_i \times p}
\]</span> and a corresponding coefficient vector <span class="math inline">\(\beta \in \mathbb{R}^{p}\)</span> we assume that
the observations are multivariate normal distributed: <span class="math display">\[
Y_i \sim N(X_i\beta, \Sigma_i)
\]</span> where the covariance matrix <span class="math inline">\(\Sigma_i \in \mathbb{R}^{m_i \times m_i}\)</span>
is derived by subsetting the overall covariance matrix <span class="math inline">\(\Sigma \in \mathbb{R}^{m \times m}\)</span>
appropriately by <span class="math display">\[
\Sigma_i = G_i^{-1/2} S_i^\top \Sigma S_i G_i^{-1/2}
\]</span> where the subsetting matrix <span class="math inline">\(S_i
\in \{0, 1\}^{m \times m_i}\)</span> contains in each of its <span class="math inline">\(m_i\)</span> columns contains a single 1
indicating which overall time point is matching <span class="math inline">\(t_{ih}\)</span>. <span class="math inline">\(G_i
\in \mathbb{R}_{\gt 0}^{m_i \times m_i}\)</span> is the diagonal weight
matrix.</p>
<p>Conditional on the design matrices <span class="math inline">\(X_i\)</span>, the coefficient vector <span class="math inline">\(\beta\)</span> and the covariance matrix <span class="math inline">\(\Sigma\)</span> we assume that the observations
are independent between the subjects.</p>
<p>We can write the linear model for all subjects together as <span class="math display">\[
Y = X\beta + \epsilon
\]</span> where <span class="math inline">\(Y \in \mathbb{R}^N\)</span>
combines all subject specific observations vectors <span class="math inline">\(Y_i\)</span> such that we have in total <span class="math inline">\(N = \sum_{i = 1}^{n}{m_i}\)</span> observations,
<span class="math inline">\(X \in \mathbb{R}^{N \times p}\)</span>
combines all subject specific design matrices and <span class="math inline">\(\epsilon \in \mathbb{R}^N\)</span> has a
multivariate normal distribution <span class="math display">\[
\epsilon \sim N(0, \Omega)
\]</span> where <span class="math inline">\(\Omega \in \mathbb{R}^{N
\times N}\)</span> is block-diagonal containing the subject specific
<span class="math inline">\(\Sigma_i\)</span> covariance matrices on the
diagonal and 0 in the remaining entries.</p>
</div>
</div>
<div class="section level3">
<h3 id="mathematical-details-of-kenward-roger-method">Mathematical Details of Kenward-Roger method<a class="anchor" aria-label="anchor" href="#mathematical-details-of-kenward-roger-method"></a>
</h3>
<p>The mathematical derivation of the Kenward-Roger method is based on
the Taylor expansion of the obtained covariance matrix of <span class="math inline">\(\hat\beta\)</span> to get a more accurate estimate
for it. All these derivations are based on the restricted maximum
likelihood. Following the same <a href="algorithm.html#covariance-matrix-model">notation</a>, the
covariance matrix, <span class="math inline">\(\Omega\)</span> can be
represented as a function of covariance matrix parameters <span class="math inline">\(\theta = (\theta_1, \dotsc,
\theta_k)^\top\)</span>, i.e. <span class="math inline">\(\Omega(\theta)\)</span>. Here after model fitting
with <code>mmrm</code>, we obtain the estimate <span class="math inline">\(\hat\beta =
\Phi(\hat\theta)X^\top\Omega(\hat\theta)^{-1}Y\)</span>, where <span class="math inline">\(\Phi(\theta) = \left\{X^\top \Omega(\theta)^{-1}
X\right\} ^{-1}\)</span> is the asymptotic covariance matrix of <span class="math inline">\(\hat\beta\)</span>. However, <span class="citation">Kackar and Harville (1984)</span> suggests that
although the <span class="math inline">\(\hat\beta\)</span> is unbiased
for <span class="math inline">\(\beta\)</span>, the covariance matrix,
<span class="math inline">\(\hat\Phi = \left\{X^\top \hat\Omega
X\right\}^{-1}\)</span> can be biased. They showed that the variability
of <span class="math inline">\(\hat\beta\)</span> can be partitioned
into two components,</p>
<p><span class="math display">\[
  \Phi_A = \Phi + \Lambda
\]</span></p>
<p>where <span class="math inline">\(\Phi\)</span> is the
variance-covariance matrix of the asymptotic distribution of <span class="math inline">\(\hat\beta\)</span> as <span class="math inline">\(n\rightarrow \infty\)</span> as defined above, and
<span class="math inline">\(\Lambda\)</span> represents the amount to
which the asymptotic variance-covariance matrix underestimates <span class="math inline">\(\Phi_A\)</span>.</p>
<p>Based on a Taylor series expansion around <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\Lambda\)</span> can be approximated by</p>
<p><span class="math display">\[
  \Lambda \simeq \Phi \left\{\sum_{h=1}^k{\sum_{j=1}^k{W_{hj}(Q_{hj} -
P_h \Phi P_j)} }\right\} \Phi
\]</span> where <span class="math display">\[
  P_h = X^\top \frac{\partial{\Omega^{-1}}}{\partial \theta_h} X
\]</span> <span class="math display">\[
  Q_{hj} = X^\top \frac{\partial{\Omega^{-1}}}{\partial \theta_h} \Omega
\frac{\partial{\Omega^{-1}}}{\partial \theta_j} X
\]</span></p>
<p><span class="math inline">\(W\)</span> is the inverse of the Hessian
matrix of the log-likelihood function of <span class="math inline">\(\theta\)</span> evaluated at the estimate <span class="math inline">\(\hat\theta\)</span>, i.e. the observed Fisher
Information matrix as a consistent estimator of the variance-covariance
matrix of <span class="math inline">\(\hat\theta\)</span>.</p>
<p>Again, based on a Taylor series expansion about <span class="math inline">\(\theta\)</span>, <span class="citation">Kenward
and Roger (1997)</span> show that <span class="math display">\[
  \hat\Phi \simeq \Phi + \sum_{h=1}^k{(\hat\theta_h -
\theta_h)\frac{\partial{\Phi}}{\partial{\theta_h}}} + \frac{1}{2}
\sum_{h=1}^k{\sum_{j=1}^k{(\hat\theta_h - \theta_h)(\hat\theta_j -
\theta_j)\frac{\partial^2{\Phi}}{\partial{\theta_h}\partial{\theta_j}}}}
\]</span> Ignoring the possible bias in <span class="math inline">\(\hat\theta\)</span>, <span class="math display">\[
  E(\hat\Phi) \simeq \Phi + \frac{1}{2}
\sum_{h=1}^k{\sum_{j=1}^k{W_{hj}\frac{\partial^2{\Phi}}{\partial{\theta_h}\partial{\theta_j}}}}
\]</span> Using previously defined notations, this can be further
written as <span class="math display">\[
  \frac{\partial^2{\Phi}}{\partial{\theta_h}\partial{\theta_j}} = \Phi
(P_h \Phi P_j + P_j \Phi P_h - Q_{hj} - Q_{jh} + R_{hj}) \Phi
\]</span> where <span class="math display">\[
  R_{hj} =
X^\top\Omega^{-1}\frac{\partial^2\Omega}{\partial{\theta_h}\partial{\theta_j}}
\Omega^{-1} X
\]</span></p>
<p>substituting <span class="math inline">\(\Phi\)</span> and <span class="math inline">\(\Lambda\)</span> back to the <span class="math inline">\(\hat\Phi_A\)</span>, we have</p>
<p><span class="math display">\[
  \hat\Phi_A = \hat\Phi + 2\hat\Phi
\left\{\sum_{h=1}^k{\sum_{j=1}^k{W_{hj}(Q_{hj} - P_h \hat\Phi P_j -
\frac{1}{4}R_{hj})} }\right\} \hat\Phi
\]</span></p>
<p>where <span class="math inline">\(\Omega(\hat\theta)\)</span>
replaces <span class="math inline">\(\Omega(\theta)\)</span> in the
right-hand side.</p>
<p>Please note that, if we ignore <span class="math inline">\(R_{hj}\)</span>, the second-order derivatives, we
will get a different estimate of adjusted covariance matrix, and we call
this the linear Kenward-Roger approximation.</p>
<div class="section level4">
<h4 id="special-considerations-for-mmrm-models">Special Considerations for mmrm models<a class="anchor" aria-label="anchor" href="#special-considerations-for-mmrm-models"></a>
</h4>
<p>In mmrm models, <span class="math inline">\(\Omega\)</span> is a
block-diagonal matrix, hence we can calculate <span class="math inline">\(P\)</span>, <span class="math inline">\(Q\)</span>
and <span class="math inline">\(R\)</span> for each subject and add them
up.</p>
<p><span class="math display">\[
  P_h = \sum_{i=1}^{N}{P_{ih}} = \sum_{i=1}^{N}{X_i^\top
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_h} X_i}
\]</span></p>
<p><span class="math display">\[
  Q_{hj} = \sum_{i=1}^{N}{Q_{ihj}} = \sum_{i=1}^{N}{X_i^\top
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_h} \Sigma_i
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_j} X_i}
\]</span></p>
<p><span class="math display">\[
  R_{hj} = \sum_{i=1}^{N}{R_{ihj}} =
\sum_{i=1}^{N}{X_i^\top\Sigma_i^{-1}\frac{\partial^2\Sigma_i}{\partial{\theta_h}\partial{\theta_j}}
\Sigma_i^{-1} X_i}
\]</span></p>
</div>
<div class="section level4">
<h4 id="derivative-of-the-overall-covariance-matrix-sigma">Derivative of the overall covariance matrix <span class="math inline">\(\Sigma\)</span><a class="anchor" aria-label="anchor" href="#derivative-of-the-overall-covariance-matrix-sigma"></a>
</h4>
<p>The derivative of the overall covariance matrix <span class="math inline">\(\Sigma\)</span> with respect to the variance
parameters can be calculated through the derivatives of the Cholesky
factor, and hence obtained through automatic differentiation, following
<a href="https://en.wikipedia.org/wiki/Matrix_calculus#Identities_in_differential_form" class="external-link">matrix
identities calculations</a>. <span class="math display">\[
  \frac{\partial{\Sigma}}{\partial{\theta_h}} =
\frac{\partial{LL^\top}}{\partial{\theta_h}} =
\frac{\partial{L}}{\partial{\theta_h}}L^\top +
L\frac{\partial{L^\top}}{\partial{\theta_h}}
\]</span></p>
<p><span class="math display">\[
  \frac{\partial^2{\Sigma}}{\partial{\theta_h}\partial{\theta_j}} =
\frac{\partial^2{L}}{\partial{\theta_h}\partial{\theta_j}}L^\top +
L\frac{\partial^2{L^\top}}{\partial{\theta_h}\partial{\theta_j}} +
\frac{\partial{L}}{\partial{\theta_h}}\frac{\partial{L^T}}{\partial{\theta_j}}
+
\frac{\partial{L}}{\partial{\theta_j}}\frac{\partial{L^\top}}{\partial{\theta_h}}
\]</span></p>
</div>
<div class="section level4">
<h4 id="derivative-of-the-sigma-1">Derivative of the <span class="math inline">\(\Sigma^{-1}\)</span><a class="anchor" aria-label="anchor" href="#derivative-of-the-sigma-1"></a>
</h4>
<p>The derivatives of <span class="math inline">\(\Sigma^{-1}\)</span>
can be calculated through</p>
<p><span class="math display">\[
  \frac{\partial{\Sigma\Sigma^{-1}}}{\partial{\theta_h}}\\
  = \frac{\partial{\Sigma}}{\partial{\theta_h}}\Sigma^{-1} +
\Sigma\frac{\partial{\Sigma^{-1}}}{\partial{\theta_h}} \\
  = 0
\]</span> <span class="math display">\[
  \frac{\partial{\Sigma^{-1}}}{\partial{\theta_h}} = - \Sigma^{-1}
\frac{\partial{\Sigma}}{\partial{\theta_h}}\Sigma^{-1}
\]</span></p>
</div>
<div class="section level4">
<h4 id="subjects-with-missed-visits">Subjects with missed visits<a class="anchor" aria-label="anchor" href="#subjects-with-missed-visits"></a>
</h4>
<p>If a subject do not have all visits, the corresponding covariance
matrix can be represented as <span class="math display">\[
  \Sigma_i = S_i^\top \Sigma S_i
\]</span></p>
<p>and the derivatives can be obtained through</p>
<p><span class="math display">\[
  \frac{\partial{\Sigma_i}}{\partial{\theta_h}} = S_i^\top
\frac{\partial{\Sigma}}{\partial{\theta_h}} S_i
\]</span></p>
<p><span class="math display">\[
  \frac{\partial^2{\Sigma_i}}{\partial{\theta_h}\partial{\theta_j}} =
S_i^\top \frac{\partial^2{\Sigma}}{\partial{\theta_h}\partial{\theta_j}}
S_i
\]</span></p>
<p>The derivative of the <span class="math inline">\(\Sigma_i^{-1}\)</span>, <span class="math inline">\(\frac{\partial\Sigma_i^{-1}}{\partial{\theta_h}}\)</span>
can be calculated through <span class="math inline">\(\Sigma_i^{-1}\)</span> and <span class="math inline">\(\frac{\partial{\Sigma_i}}{\partial{\theta_h}}\)</span>
using the above.</p>
</div>
<div class="section level4">
<h4 id="scenario-under-group-specific-covariance-estimates">Scenario under group specific covariance estimates<a class="anchor" aria-label="anchor" href="#scenario-under-group-specific-covariance-estimates"></a>
</h4>
<p>When fitting grouped <code>mmrm</code> models, the covariance matrix
for subject i of group <span class="math inline">\(g(i)\)</span>, can be
written as <span class="math display">\[
  \Sigma_i = S_i^\top \Sigma_{g(i)} S_i$.
\]</span> Assume there are <span class="math inline">\(B\)</span>
groups, the number of parameters is increased by <span class="math inline">\(B\)</span> times. With the fact that for each
group, the corresponding <span class="math inline">\(\theta\)</span>
will not affect other parts, we will have block-diagonal <span class="math inline">\(P\)</span>, <span class="math inline">\(Q\)</span>
and <span class="math inline">\(R\)</span> matrices, where the blocks
are given by:</p>
<p><span class="math display">\[
P_h = \begin{pmatrix}
P_{h, 1} &amp; \dots &amp; P_{h, B} \\
\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
Q_{hj} = \begin{pmatrix}
Q_{hj, 1} &amp; 0 &amp; \dots &amp; \dots &amp; 0 \\
0 &amp; Q_{hj, 2} &amp; 0 &amp; \dots &amp; 0\\
\vdots &amp; &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; &amp; &amp; \ddots &amp; \vdots \\
0 &amp; \dots &amp; \dots &amp; 0 &amp; Q_{hj, B}
\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
R_{hj} = \begin{pmatrix}
R_{hj, 1} &amp; 0 &amp; \dots &amp; \dots &amp; 0 \\
0 &amp; R_{hj, 2} &amp; 0 &amp; \dots &amp; 0\\
\vdots &amp; &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; &amp; &amp; \ddots &amp; \vdots \\
0 &amp; \dots &amp; \dots &amp; 0 &amp; R_{hj, B}
\end{pmatrix}
\]</span></p>
<p>Use <span class="math inline">\(P_{j, b}\)</span> to denote the block
diagonal part for group <span class="math inline">\(b\)</span>, we have
<span class="math display">\[
  P_{h,b} = \sum_{g(i) = b}{P_{ih}} = \sum_{g(i) = b}{X_i^\top
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_h} X_i}
\]</span></p>
<p><span class="math display">\[
  Q_{hj,b} = \sum_{g(i) = b}{Q_{ihj}} = \sum_{g(i) = b}{X_i^\top
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_h} \Sigma_i
\frac{\partial{\Sigma_i^{-1}}}{\partial \theta_j} X_i}
\]</span></p>
<p><span class="math display">\[
  R_{hj,b} = \sum_{g(i) = b}{R_{ihj}} = \sum_{g(i) =
b}{X_i^\top\Sigma_i^{-1}\frac{\partial^2\Sigma_i}{\partial{\theta_h}\partial{\theta_j}}
\Sigma_i^{-1} X_i}
\]</span></p>
<p>Similarly for <span class="math inline">\(R\)</span>.</p>
</div>
<div class="section level4">
<h4 id="scenario-under-weighted-mmrm">Scenario under weighted mmrm<a class="anchor" aria-label="anchor" href="#scenario-under-weighted-mmrm"></a>
</h4>
<p>Under weights mmrm model, the covariance matrix for subject <span class="math inline">\(i\)</span>, can be represented as</p>
<p><span class="math display">\[
  \Sigma_i = G_i^{-1/2} S_i^\top \Sigma S_i G_i^{-1/2}
\]</span></p>
<p>Where <span class="math inline">\(G_i\)</span> is a diagonal matrix
of the weights. Then, when deriving <span class="math inline">\(P\)</span>, <span class="math inline">\(Q\)</span>
and <span class="math inline">\(R\)</span>, there are no mathematical
differences as they are constant, and having <span class="math inline">\(G_i\)</span> in addition to <span class="math inline">\(S_i\)</span> does not change the algorithms and we
can simply multiply the formulas with <span class="math inline">\(G_i^{-1/2}\)</span>, similarly as above for the
subsetting matrix.</p>
</div>
</div>
<div class="section level3">
<h3 id="inference">Inference<a class="anchor" aria-label="anchor" href="#inference"></a>
</h3>
<p>Suppose we are testing the linear combination of <span class="math inline">\(\beta\)</span>, <span class="math inline">\(C\beta\)</span> with <span class="math inline">\(C
\in \mathbb{R}^{c\times p}\)</span>, we can use the following
F-statistic <span class="math display">\[
  F = \frac{1}{c} (\hat\beta - \beta)^\top  C (C^\top \hat\Phi_A C)^{-1}
C^\top (\hat\beta - \beta)
\]</span> and <span class="math display">\[
  F^* = \lambda F
\]</span> follows exact <span class="math inline">\(F_{c,m}\)</span>
distribution.</p>
<p>When we have only one coefficient to test, then <span class="math inline">\(C\)</span> is a column vector containing a single
<span class="math inline">\(1\)</span> inside. We can still follow the
same calculations as for the multi-dimensional case. This recovers the
degrees of freedom results of the Satterthwaite method.</p>
<p><span class="math inline">\(\lambda\)</span> and <span class="math inline">\(m\)</span> can be calculated through</p>
<p><span class="math display">\[
  M = C (C^\top \Phi C)^{-1} C^\top
\]</span></p>
<p><span class="math display">\[
  A_1 = \sum_{h=1}^k{\sum_{j=1}^k{W_{hj} tr(M \Phi P_h \Phi) tr(M \Phi
P_j \Phi)}}
\]</span></p>
<p><span class="math display">\[
  A_2 = \sum_{h=1}^k{\sum_{j=1}^k{W_{hj} tr(M \Phi P_h \Phi M \Phi P_j
\Phi)}}
\]</span></p>
<p><span class="math display">\[
  B = \frac{1}{2c}(A_1 + 6A_2)
\]</span></p>
<p><span class="math display">\[
  g = \frac{(c+1)A_1 - (c+4)A_2}{(c+2)A_2}
\]</span></p>
<p><span class="math display">\[
  c_1 = \frac{g}{3c+2(1-g)}
\]</span></p>
<p><span class="math display">\[
  c_2 = \frac{c-g}{3c+2(1-g)}
\]</span></p>
<p><span class="math display">\[
  c_3 = \frac{c+2-g}{3c+2(1-g)}
\]</span> <span class="math display">\[E^*={\left\{1-\frac{A_2}{c}\right\}}^{-1}\]</span>
<span class="math display">\[V^*=\frac{2}{c}{\left\{\frac{1+c_1
B}{(1-c_2 B)^2(1-c_3 B)}\right\}}\]</span></p>
<p><span class="math display">\[\rho =
\frac{V^{*}}{2(E^*)^2}\]</span></p>
<p><span class="math display">\[m = 4 + \frac{c+2}{c\rho - 1}\]</span>
<span class="math display">\[\lambda = \frac{m}{E^*(m-2)}\]</span></p>
</div>
<div class="section level3">
<h3 id="parameterization-methods-and-kenward-roger">Parameterization methods and Kenward-Roger<a class="anchor" aria-label="anchor" href="#parameterization-methods-and-kenward-roger"></a>
</h3>
<p>While the Kenward-Roger adjusted covariance matrix is adopting a
Taylor series to approximate the true value, the choices of
parameterization can change the result. In a simple example of
unstructured covariance structure, in our current approach, where the
parameters are elements of the Cholesky factor of <span class="math inline">\(\Sigma\)</span> (see <a href="covariance.html">parameterization</a>), the second-order
derivatives of <span class="math inline">\(\Sigma\)</span> over our
parameters, are non-zero matrices. However, if we use the elements of
<span class="math inline">\(\Sigma\)</span> as our parameters, then the
second-order derivatives are zero matrices. However, the differences can
be small and will not affect the inference. If you would like to match
SAS results for the unstructured covariance model, you can use the
linear Kenward-Roger approximation.</p>
</div>
<div class="section level3">
<h3 id="implementations-in-mmrm">Implementations in <code>mmrm</code><a class="anchor" aria-label="anchor" href="#implementations-in-mmrm"></a>
</h3>
<p>In package <code>mmrm</code>, we have implemented Kenward-Roger
calculations based on the previous sections. Specially, for the
first-order and second-order derivatives, we use automatic
differentiation to obtain the results easily for non-spatial covariance
structure. For spatial covariance structure, we derive the exact
results.</p>
<div class="section level4">
<h4 id="spatial-exponential-derivatives">Spatial Exponential Derivatives<a class="anchor" aria-label="anchor" href="#spatial-exponential-derivatives"></a>
</h4>
<p>For spatial exponential covariance structure, we have</p>
<p><span class="math display">\[\theta = (\theta_1,\theta_2)\]</span>
<span class="math display">\[\sigma = e^{\theta_1}\]</span> <span class="math display">\[\rho = \frac{e^{\theta_2}}{1 +
e^{\theta_2}}\]</span></p>
<p><span class="math display">\[\Sigma_{ij} = \sigma
\rho^{d_{ij}}\]</span> where <span class="math inline">\(d_{ij}\)</span>
is the distance between time point <span class="math inline">\(i\)</span> and time point <span class="math inline">\(j\)</span>.</p>
<p>So the first-order derivatives can be written as:</p>
<p><span class="math display">\[
  \frac{\partial{\Sigma_{ij}}}{\partial\theta_1} =
\frac{\partial\sigma}{\partial\theta_1} \rho^{d_{ij}}\\
  = e^{\theta_1}\rho^{d_{ij}} \\
  = \Sigma_{ij}
\]</span></p>
<p><span class="math display">\[
  \frac{\partial{\Sigma_{ij}}}{\partial\theta_2} =
\sigma\frac{\partial{\rho^{d_{ij}}}}{\partial\theta_2} \\
  = \sigma\rho^{d_{ij}-1}{d_{ij}}\frac{\partial\rho}{\partial\theta_2}\\
  = \sigma\rho^{d_{ij}-1}{d_{ij}}\rho(1-\rho) \\
  = \sigma \rho^{d_{ij}} {d_{ij}} (1-\rho)
\]</span></p>
<p>Second-order derivatives can be written as:</p>
<p><span class="math display">\[
  \frac{\partial^2{\Sigma_{ij}}}{\partial\theta_1\partial\theta_1}\\
  = \frac{\partial\Sigma_{ij}}{\partial\theta_1}\\
  = \Sigma_{ij}
\]</span></p>
<p><span class="math display">\[
  \frac{\partial^2{\Sigma_{ij}}}{\partial\theta_1\partial\theta_2} =
\frac{\partial^2{\Sigma_{ij}}}{\partial\theta_2\partial\theta_1} \\
  = \frac{\partial\Sigma_{ij}}{\partial\theta_2}\\
  = \sigma\rho^{d_{ij}-1}{d_{ij}}\rho(1-\rho)\\
  = \sigma\rho^{d_{ij}}{d_{ij}}(1-\rho)
\]</span></p>
<p><span class="math display">\[
  \frac{\partial^2{\Sigma_{ij}}}{\partial\theta_2\partial\theta_2}\\
  =
\frac{\partial{\sigma\rho^{d_{ij}}{d_{ij}}(1-\rho)}}{\partial\theta_2}\\
  = \sigma\rho^{d_{ij}}{d_{ij}}(1-\rho)(d_{ij} (1-\rho) - \rho)
\]</span></p>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-kackar1984" class="csl-entry">
Kackar RN, Harville DA (1984). <span>“Approximations for Standard Errors
of Estimators of Fixed and Random Effects in Mixed Linear
Models.”</span> <em>Journal of the American Statistical
Association</em>, <strong>79</strong>(388), 853–862. <a href="https://doi.org/10.1080/01621459.1984.10477102" class="external-link">https://doi.org/10.1080/01621459.1984.10477102.</a>
</div>
<div id="ref-kenward1997" class="csl-entry">
Kenward MG, Roger JH (1997). <span>“Small Sample Inference for Fixed
Effects from Restricted Maximum Likelihood.”</span> <em>Biometrics</em>,
<strong>53</strong>(3), 983–997. <a href="https://doi.org/10.2307/2533558" class="external-link">https://doi.org/10.2307/2533558.</a>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Daniel Sabanes Bove, Julia Dedic, Doug Kelkhoff, Kevin Kunzmann, Brian Matthew Lang, Liming Li, Christian Stock, Ya Wang, Dan James, Jonathan Sidi, Daniel Leibovitz, Daniel D. Sjoberg, Boehringer Ingelheim Ltd., Gilead Sciences, Inc., F. Hoffmann-La Roche AG, Merck Sharp &amp; Dohme, Inc., AstraZeneca plc.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
